{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai0xRngO4xZL",
    "colab_type": "text"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "-X8ZS575g5BP",
    "colab_type": "code",
    "outputId": "9794f0fc-5b48-43e1-8fbc-29ab2a43056b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/3c/d5fa084dd3a82ffc645aba78c417e6072ff48552e3301b1fa3bd711e03d4/pytorch_pretrained_bert-0.6.1-py3-none-any.whl (114kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 8.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.128)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.128 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.128)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.128->boto3->pytorch_pretrained_bert) (2.5.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.128->boto3->pytorch_pretrained_bert) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.128->boto3->pytorch_pretrained_bert) (1.11.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "pl_URz9EhMjY",
    "colab_type": "code",
    "outputId": "0e757550-d99b-4e34-bcae-de68f0a15323",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining ,BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9alyLJZ41kx",
    "colab_type": "text"
   },
   "source": [
    "# Bert Generate One By One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "u2-W9XeqYRtL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
    "target_text = \"我搭公車上學\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "MdTArBzKhPb2",
    "colab_type": "code",
    "outputId": "330efa5a-16c6-4bb6-bf9d-889760ac2615",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318.0
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109540/109540 [00:00<00:00, 648370.92B/s]\n",
      "100%|██████████| 382072689/382072689 [00:12<00:00, 30653301.52B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, 2769] 2769\n",
      "9 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3022] 3022\n",
      "10 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1062] 1062\n",
      "11 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 6722] 6722\n",
      "12 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '車', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 677] 677\n",
      "13 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '車', '上', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2119] 2119\n",
      "14 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '車', '上', '學', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 102] 102\n",
      "15 1\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "modelpath = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
    "model = BertForMaskedLM.from_pretrained(modelpath)\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "example_pair = dict()\n",
    "\n",
    "for i in range(0,len(target_text)+1):\n",
    "  tokenized_text = tokenizer.tokenize(input_text)\n",
    "  tokenized_text.extend(target_text[:i])\n",
    "  tokenized_text.append('[MASK]')\n",
    "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#   for _ in range(512-len(indexed_tokens)):\n",
    "#     indexed_tokens.append(0)\n",
    "  tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "  \n",
    "  loss_ids = [-1] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
    "  if i == len(target_text):\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))[0])\n",
    "  else:\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(target_text[i])[0])\n",
    "#   for _ in range(512-len(loss_ids)):\n",
    "#     loss_ids.append(-1)\n",
    "  loss_tensors = torch.tensor([loss_ids]).to('cuda')\n",
    "  \n",
    "  example_pair[tokens_tensor] = loss_tensors\n",
    "  print(tokenized_text,loss_ids,loss_ids[-1])\n",
    "  print(len(indexed_tokens),len(loss_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a6PRnq8jwb39",
    "colab_type": "code",
    "outputId": "9f2f1fc7-92da-4f05-aff0-2398f888fda5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,   103]],\n",
      "       device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 2769]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,   103]],\n",
      "       device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 3022]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "           103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 1062]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,   103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 6722]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,  6722,   103]], device='cuda:0'): tensor([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 677]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,  6722,   677,   103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1, 2119]], device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,  6722,   677,  2119,   103]], device='cuda:0'): tensor([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         102]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(example_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "m4WdqbT06r44",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# hack to remove pooler, which is not used\n",
    "# thus it produce None grad that break apex\n",
    "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                             lr=5e-5,\n",
    "                             warmup=0.1,\n",
    "                             t_total=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "CmQ3PhWa7I3z",
    "colab_type": "code",
    "outputId": "7d1271e1-34de-4453-c2f2-8b82cafe100a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : 44.37307119369507\n",
      "step 1 : 24.271377563476562\n",
      "step 2 : 12.52522087097168\n",
      "step 3 : 22.794570922851562\n",
      "step 4 : 54.069153785705566\n",
      "step 5 : 26.595879077911377\n",
      "step 6 : 17.794955253601074\n",
      "step 7 : 19.63413095474243\n",
      "step 8 : 14.428961277008057\n",
      "step 9 : 17.612611770629883\n",
      "step 10 : 3.119110107421875\n",
      "step 11 : 0.34311676025390625\n",
      "step 12 : 4.273902893066406\n",
      "step 13 : 0.00643157958984375\n",
      "step 14 : 0.012725830078125\n",
      "step 15 : 0.002643585205078125\n",
      "step 16 : 0.0011348724365234375\n",
      "step 17 : 0.0010509490966796875\n",
      "step 18 : 0.0018711090087890625\n",
      "step 19 : 0.00031280517578125\n",
      "step 20 : 0.000392913818359375\n",
      "step 21 : 0.0003414154052734375\n",
      "step 22 : 0.0001430511474609375\n",
      "step 23 : 0.000186920166015625\n",
      "step 24 : 0.00023651123046875\n",
      "step 25 : 0.000225067138671875\n",
      "step 26 : 9.72747802734375e-05\n",
      "step 27 : 0.000118255615234375\n",
      "step 28 : 0.000141143798828125\n",
      "step 29 : 0.0001659393310546875\n",
      "step 30 : 0.0002574920654296875\n",
      "step 31 : 0.0001087188720703125\n",
      "step 32 : 15.795350074768066\n",
      "step 33 : 0.0002117156982421875\n",
      "step 34 : 0.0001316070556640625\n",
      "step 35 : 9.1552734375e-05\n",
      "step 36 : 0.0001544952392578125\n",
      "step 37 : 8.0108642578125e-05\n",
      "step 38 : 0.0001316070556640625\n",
      "step 39 : 0.0001811981201171875\n",
      "step 40 : 0.000240325927734375\n",
      "step 41 : 0.0005550384521484375\n",
      "step 42 : 0.0001392364501953125\n",
      "step 43 : 0.00029754638671875\n",
      "step 44 : 0.000164031982421875\n",
      "step 45 : 0.0003414154052734375\n",
      "step 46 : 0.0001697540283203125\n",
      "step 47 : 6.103515625e-05\n",
      "step 48 : 0.000118255615234375\n",
      "step 49 : 0.0001087188720703125\n",
      "step 50 : 0.000240325927734375\n",
      "step 51 : 0.0002803802490234375\n",
      "step 52 : 0.000110626220703125\n",
      "step 53 : 0.0001506805419921875\n",
      "step 54 : 0.0002803802490234375\n",
      "step 55 : 0.0001983642578125\n",
      "step 56 : 7.82012939453125e-05\n",
      "step 57 : 8.58306884765625e-05\n",
      "step 58 : 0.0003871917724609375\n",
      "step 59 : 0.0001392364501953125\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(0,60):\n",
    "  eveloss = 0\n",
    "  for k,v in example_pair.items():\n",
    "    loss = model(k,masked_lm_labels=v)\n",
    "    eveloss += loss.mean().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "epTye3VAZ_5r",
    "colab_type": "code",
    "outputId": "456c52d6-a873-4cd7-c591-0490e9fd93fa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我']\n",
      "['搭']\n",
      "['公']\n",
      "['車']\n",
      "['上']\n",
      "['學']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for k,v in example_pair.items():\n",
    "    predictions = model(k)\n",
    "    predicted_index = torch.argmax(predictions[0,len(predictions[0])-1]).item()\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    if '[SEP]' in predicted_token:\n",
    "      break\n",
    "    print(predicted_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jJ9Wkaz5AaL",
    "colab_type": "text"
   },
   "source": [
    "# Bert Generate One Time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wnIbjZHbYUa4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
    "target_text = \"我搭公車上學\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "DMmvXGZe5mLM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "modelpath = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
    "model = BertForMaskedLM.from_pretrained(modelpath)\n",
    "model.to('cuda')\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(input_text)\n",
    "for i in target_text:\n",
    "  tokenized_text.append('[MASK]')\n",
    "# tokenized_text.append('[SEP]')\n",
    "for _ in range(128-len(tokenized_text)):\n",
    "  tokenized_text.append('[MASK]')\n",
    "# tokenized_text.append('[MASK]')\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "\n",
    "loss_ids = []\n",
    "loss_ids = [-1] * (len(tokenizer.tokenize(input_text)))\n",
    "# loss_ids.extend(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_text)))\n",
    "for i in target_text:\n",
    "  loss_ids.append(tokenizer.convert_tokens_to_ids(i)[0])\n",
    "loss_ids.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "for _ in range(128-len(loss_ids)):\n",
    "  loss_ids.append(-1)\n",
    "loss_tensors = torch.tensor([loss_ids]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "dxSZyq6D87YX",
    "colab_type": "code",
    "outputId": "9dc17c95-b8c5-4327-b238-e9fa66d196df",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103]],\n",
      "       device='cuda:0') tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 2769, 3022, 1062, 6722,\n",
      "          677, 2119,  102,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1]], device='cuda:0')\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_tensor,loss_tensors)\n",
    "print(tokenizer.convert_ids_to_tokens(indexed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "TtWr0Zs158ZF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# # Prepare optimizer\n",
    "# param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# # hack to remove pooler, which is not used\n",
    "# # thus it produce None grad that break apex\n",
    "# param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.05},\n",
    "#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.01}\n",
    "#         ]\n",
    "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "#                              lr=5e-5)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-7)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 5e-5, momentum=0.9)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "RQfnhXCy5_Ag",
    "colab_type": "code",
    "outputId": "af10ca8a-9a7b-4953-f240-69d3c59b9470",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5290.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : 7.913342475891113\n",
      "step 1 : 7.833029270172119\n",
      "step 2 : 7.197516441345215\n",
      "step 3 : 6.325068473815918\n",
      "step 4 : 5.70965576171875\n",
      "step 5 : 5.5573506355285645\n",
      "step 6 : 4.576362609863281\n",
      "step 7 : 4.289361000061035\n",
      "step 8 : 4.3420515060424805\n",
      "step 9 : 4.592452526092529\n",
      "step 10 : 4.3097662925720215\n",
      "step 11 : 4.651139736175537\n",
      "step 12 : 4.5207648277282715\n",
      "step 13 : 4.477480411529541\n",
      "step 14 : 4.2064900398254395\n",
      "step 15 : 4.258938789367676\n",
      "step 16 : 4.068099498748779\n",
      "step 17 : 3.940248727798462\n",
      "step 18 : 4.226219654083252\n",
      "step 19 : 4.136264801025391\n",
      "step 20 : 4.031257629394531\n",
      "step 21 : 4.052146911621094\n",
      "step 22 : 4.0309343338012695\n",
      "step 23 : 3.9492135047912598\n",
      "step 24 : 3.657867431640625\n",
      "step 25 : 3.862555980682373\n",
      "step 26 : 3.7650206089019775\n",
      "step 27 : 3.5912110805511475\n",
      "step 28 : 3.6331944465637207\n",
      "step 29 : 3.9080066680908203\n",
      "step 30 : 3.6006791591644287\n",
      "step 31 : 3.616935968399048\n",
      "step 32 : 3.6273269653320312\n",
      "step 33 : 3.4186439514160156\n",
      "step 34 : 3.361997365951538\n",
      "step 35 : 3.232696056365967\n",
      "step 36 : 3.52933669090271\n",
      "step 37 : 3.5277061462402344\n",
      "step 38 : 3.4441311359405518\n",
      "step 39 : 3.1852688789367676\n",
      "step 40 : 3.068091630935669\n",
      "step 41 : 3.2665083408355713\n",
      "step 42 : 3.080008029937744\n",
      "step 43 : 3.1224658489227295\n",
      "step 44 : 2.9322803020477295\n",
      "step 45 : 2.863637924194336\n",
      "step 46 : 2.8540420532226562\n",
      "step 47 : 2.8729798793792725\n",
      "step 48 : 2.638160228729248\n",
      "step 49 : 2.4272518157958984\n",
      "step 50 : 2.71510648727417\n",
      "step 51 : 2.541132688522339\n",
      "step 52 : 2.5047762393951416\n",
      "step 53 : 2.6105880737304688\n",
      "step 54 : 1.9781339168548584\n",
      "step 55 : 1.9441291093826294\n",
      "step 56 : 2.1932919025421143\n",
      "step 57 : 2.159261465072632\n",
      "step 58 : 2.2510900497436523\n",
      "step 59 : 2.0489025115966797\n",
      "step 60 : 1.9925830364227295\n",
      "step 61 : 2.0157437324523926\n",
      "step 62 : 1.83278489112854\n",
      "step 63 : 1.6471681594848633\n",
      "step 64 : 1.5999395847320557\n",
      "step 65 : 1.8291329145431519\n",
      "step 66 : 1.865471601486206\n",
      "step 67 : 2.212336778640747\n",
      "step 68 : 1.5861409902572632\n",
      "step 69 : 2.3091835975646973\n",
      "step 70 : 1.996158242225647\n",
      "step 71 : 2.0834097862243652\n",
      "step 72 : 1.6751326322555542\n",
      "step 73 : 2.021115779876709\n",
      "step 74 : 1.7128123044967651\n",
      "step 75 : 1.299766182899475\n",
      "step 76 : 1.3418318033218384\n",
      "step 77 : 1.5672235488891602\n",
      "step 78 : 1.554721474647522\n",
      "step 79 : 1.3490718603134155\n",
      "step 80 : 2.143139362335205\n",
      "step 81 : 1.7476389408111572\n",
      "step 82 : 1.6365439891815186\n",
      "step 83 : 1.2163630723953247\n",
      "step 84 : 2.938359498977661\n",
      "step 85 : 1.0602567195892334\n",
      "step 86 : 1.33014714717865\n",
      "step 87 : 1.7363799810409546\n",
      "step 88 : 1.4378411769866943\n",
      "step 89 : 1.2095121145248413\n",
      "step 90 : 1.2718843221664429\n",
      "step 91 : 1.3220192193984985\n",
      "step 92 : 1.2332451343536377\n",
      "step 93 : 0.9844916462898254\n",
      "step 94 : 1.29464852809906\n",
      "step 95 : 1.306981086730957\n",
      "step 96 : 0.9789025187492371\n",
      "step 97 : 1.3268163204193115\n",
      "step 98 : 1.179093599319458\n",
      "step 99 : 0.8877961039543152\n",
      "step 100 : 1.1054086685180664\n",
      "step 101 : 1.0813977718353271\n",
      "step 102 : 1.0766011476516724\n",
      "step 103 : 0.8238755464553833\n",
      "step 104 : 0.9189795255661011\n",
      "step 105 : 1.1906391382217407\n",
      "step 106 : 0.5976792573928833\n",
      "step 107 : 0.6830437779426575\n",
      "step 108 : 0.7761771082878113\n",
      "step 109 : 0.5914703011512756\n",
      "step 110 : 0.5983243584632874\n",
      "step 111 : 0.9280140995979309\n",
      "step 112 : 1.0083562135696411\n",
      "step 113 : 0.6310529708862305\n",
      "step 114 : 0.39636093378067017\n",
      "step 115 : 0.7182576060295105\n",
      "step 116 : 0.37458691000938416\n",
      "step 117 : 0.7941285371780396\n",
      "step 118 : 0.35499873757362366\n",
      "step 119 : 0.5166822075843811\n",
      "step 120 : 0.14390699565410614\n",
      "step 121 : 0.5186410546302795\n",
      "step 122 : 0.12263625115156174\n",
      "step 123 : 0.3159002661705017\n",
      "step 124 : 0.28471946716308594\n",
      "step 125 : 0.43201854825019836\n",
      "step 126 : 0.3130081593990326\n",
      "step 127 : 0.2788824439048767\n",
      "step 128 : 0.2701137959957123\n",
      "step 129 : 0.40857505798339844\n",
      "step 130 : 0.1467811018228531\n",
      "step 131 : 0.10585485398769379\n",
      "step 132 : 0.16690881550312042\n",
      "step 133 : 0.36910152435302734\n",
      "step 134 : 0.15273775160312653\n",
      "step 135 : 0.23997987806797028\n",
      "step 136 : 0.019033703953027725\n",
      "step 137 : 0.13931791484355927\n",
      "step 138 : 0.20446886122226715\n",
      "step 139 : 0.03363118693232536\n",
      "step 140 : 0.27058520913124084\n",
      "step 141 : 0.42665794491767883\n",
      "step 142 : 0.21620668470859528\n",
      "step 143 : 0.11303602159023285\n",
      "step 144 : 0.4565868377685547\n",
      "step 145 : 0.08169623464345932\n",
      "step 146 : 0.06721986830234528\n",
      "step 147 : 0.029532568529248238\n",
      "step 148 : 0.0182200837880373\n",
      "step 149 : 0.1296495646238327\n",
      "step 150 : 0.01715632900595665\n",
      "step 151 : 0.036151885986328125\n",
      "step 152 : 0.07706451416015625\n",
      "step 153 : 0.2613397240638733\n",
      "step 154 : 0.11421803385019302\n",
      "step 155 : 0.04703821614384651\n",
      "step 156 : 0.9960566759109497\n",
      "step 157 : 0.05726705119013786\n",
      "step 158 : 0.019573483616113663\n",
      "step 159 : 0.24197959899902344\n",
      "step 160 : 0.1230643168091774\n",
      "step 161 : 0.6597734093666077\n",
      "step 162 : 0.009563990868628025\n",
      "step 163 : 3.056791305541992\n",
      "step 164 : 0.04194531962275505\n",
      "step 165 : 0.0481240414083004\n",
      "step 166 : 0.015704018995165825\n",
      "step 167 : 0.0497371144592762\n",
      "step 168 : 0.12608201801776886\n",
      "step 169 : 0.20319557189941406\n",
      "step 170 : 0.0036670139525085688\n",
      "step 171 : 0.00488226767629385\n",
      "step 172 : 0.2012481689453125\n",
      "step 173 : 0.002960477489978075\n",
      "step 174 : 0.008483069017529488\n",
      "step 175 : 0.0181307103484869\n",
      "step 176 : 0.04133524373173714\n",
      "step 177 : 0.00305938720703125\n",
      "step 178 : 0.028586795553565025\n",
      "step 179 : 0.05765097588300705\n",
      "step 180 : 0.019239425659179688\n",
      "step 181 : 0.05654880031943321\n",
      "step 182 : 0.004998070653527975\n",
      "step 183 : 0.03512436896562576\n",
      "step 184 : 0.027407782152295113\n",
      "step 185 : 0.0028348651248961687\n",
      "step 186 : 0.003379549365490675\n",
      "step 187 : 0.03843552619218826\n",
      "step 188 : 0.004937308374792337\n",
      "step 189 : 0.005481175146996975\n",
      "step 190 : 0.0032326835207641125\n",
      "step 191 : 0.0021547588985413313\n",
      "step 192 : 0.0029204231686890125\n",
      "step 193 : 0.017324719578027725\n",
      "step 194 : 0.0134419035166502\n",
      "step 195 : 0.012366430833935738\n",
      "step 196 : 0.01083428505808115\n",
      "step 197 : 0.004296166356652975\n",
      "step 198 : 0.0050577437505126\n",
      "step 199 : 0.0078370226547122\n",
      "step 200 : 0.0013874599244445562\n",
      "step 201 : 0.0017664773622527719\n",
      "step 202 : 0.0051422119140625\n",
      "step 203 : 0.007668631616979837\n",
      "step 204 : 0.0068746292963624\n",
      "step 205 : 0.0018555776914581656\n",
      "step 206 : 0.011963163502514362\n",
      "step 207 : 0.009174891747534275\n",
      "step 208 : 0.0013234274229034781\n",
      "step 209 : 0.026727130636572838\n",
      "step 210 : 0.0005482264677993953\n",
      "step 211 : 0.003975186962634325\n",
      "step 212 : 0.0016316005494445562\n",
      "step 213 : 0.003011158434674144\n",
      "step 214 : 0.0028501239139586687\n",
      "step 215 : 0.0019457681337371469\n",
      "step 216 : 0.0014062608825042844\n",
      "step 217 : 0.0008019038359634578\n",
      "step 218 : 0.0006019047577865422\n",
      "step 219 : 0.0018542153993621469\n",
      "step 220 : 0.0076353889890015125\n",
      "step 221 : 0.0011700221803039312\n",
      "step 222 : 0.0015953609254211187\n",
      "step 223 : 0.0035923549439758062\n",
      "step 224 : 0.0025896343868225813\n",
      "step 225 : 0.0008833748870529234\n",
      "step 226 : 0.0013419559691101313\n",
      "step 227 : 0.0011157989501953125\n",
      "step 228 : 0.0006223405944183469\n",
      "step 229 : 0.00215503154322505\n",
      "step 230 : 0.00067901611328125\n",
      "step 231 : 0.0010730198118835688\n",
      "step 232 : 0.0044615608640015125\n",
      "step 233 : 0.0009392329375259578\n",
      "step 234 : 0.0015615735901519656\n",
      "step 235 : 0.005328587256371975\n",
      "step 236 : 0.0010266985045745969\n",
      "step 237 : 0.0017177036497741938\n",
      "step 238 : 0.0009806497255340219\n",
      "step 239 : 0.0009389604674652219\n",
      "step 240 : 0.0008681160979904234\n",
      "step 241 : 0.0008051735931076109\n",
      "step 242 : 0.0031514849979430437\n",
      "step 243 : 0.0013070787535980344\n",
      "step 244 : 0.0010474069276824594\n",
      "step 245 : 0.00195666728541255\n",
      "step 246 : 0.0013277871767058969\n",
      "step 247 : 0.000514984130859375\n",
      "step 248 : 0.0005694798310287297\n",
      "step 249 : 0.0022256034426391125\n",
      "step 250 : 0.0005479539977386594\n",
      "step 251 : 0.0015024457825347781\n",
      "step 252 : 0.010113035328686237\n",
      "step 253 : 0.0008629389922134578\n",
      "step 254 : 0.0014471326721832156\n",
      "step 255 : 0.0016602107789367437\n",
      "step 256 : 0.0011667524231597781\n",
      "step 257 : 0.031465258449316025\n",
      "step 258 : 0.0021487644407898188\n",
      "step 259 : 0.0006814684020355344\n",
      "step 260 : 0.0015866415342316031\n",
      "step 261 : 0.0014997209655120969\n",
      "step 262 : 0.002365384716540575\n",
      "step 263 : 0.0008760179625824094\n",
      "step 264 : 0.0011264255736023188\n",
      "step 265 : 0.0012008121702820063\n",
      "step 266 : 0.00036076136166229844\n",
      "step 267 : 0.00127410888671875\n",
      "step 268 : 0.0015653882874175906\n",
      "step 269 : 0.005958284717053175\n",
      "step 270 : 0.001996448962017894\n",
      "step 271 : 0.0010487692197784781\n",
      "step 272 : 0.026752471923828125\n",
      "step 273 : 0.0005986350006423891\n",
      "step 274 : 0.002947398694232106\n",
      "step 275 : 0.0009969983948394656\n",
      "step 276 : 0.0013245174195617437\n",
      "step 277 : 0.034785814583301544\n",
      "step 278 : 0.0011144365416839719\n",
      "step 279 : 0.6973615288734436\n",
      "step 280 : 0.0008634839905425906\n",
      "step 281 : 0.0011781965149566531\n",
      "step 282 : 0.0037430354859679937\n",
      "step 283 : 0.0052296775393188\n",
      "step 284 : 0.0008784703095443547\n",
      "step 285 : 0.10502297431230545\n",
      "step 286 : 0.0009389604674652219\n",
      "step 287 : 0.011853626929223537\n",
      "step 288 : 0.002768107922747731\n",
      "step 289 : 0.0039730072021484375\n",
      "step 290 : 0.008652006275951862\n",
      "step 291 : 0.0020108905155211687\n",
      "step 292 : 0.0011286054505035281\n",
      "step 293 : 0.005363191943615675\n",
      "step 294 : 0.0032283237669616938\n",
      "step 295 : 0.003979274071753025\n",
      "step 296 : 0.004879542626440525\n",
      "step 297 : 0.005062648095190525\n",
      "step 298 : 0.0021236964967101812\n",
      "step 299 : 0.007640293799340725\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(0,300):\n",
    "  loss = model(tokens_tensor,masked_lm_labels=loss_tensors)\n",
    "  eveloss = loss.mean().item()\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a1tz6P9N4e3g",
    "colab_type": "code",
    "outputId": "908553ac-871a-49f8-ba43-862fd167a22d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我']\n",
      "['搭']\n",
      "['公']\n",
      "['車']\n",
      "['上']\n",
      "['學']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  predictions = model(tokens_tensor)\n",
    "  start = len(tokenizer.tokenize(input_text))\n",
    "  while start < len(predictions[0]):\n",
    "    predicted_index = torch.argmax(predictions[0,start]).item()\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    if '[SEP]' in predicted_token:\n",
    "        break\n",
    "    print(predicted_token)\n",
    "    start+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_Lf5xx8ea9p",
    "colab_type": "text"
   },
   "source": [
    "# Bert Generate LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vgGoh0YfJQKf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
    "target_text = \"我搭公車上學\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iMM-Kq7aKden",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "modelpath = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
    "example_pair = dict()\n",
    "\n",
    "for i in range(0,len(target_text)+1):\n",
    "  tokenized_text = tokenizer.tokenize(input_text)\n",
    "  tokenized_text.extend(target_text[:i])\n",
    "  tokenized_text.append('[MASK]')\n",
    "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "  tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "  \n",
    "  loss_ids = [-1] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
    "  if i == len(target_text):\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))[0])\n",
    "  else:\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(target_text[i])[0])\n",
    "  loss_tensors = torch.tensor([loss_ids]).to('cuda')\n",
    "  \n",
    "  example_pair[tokens_tensor] = loss_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a-7whGubegWn",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class BertLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        modelpath = \"bert-base-chinese\"\n",
    "        self.bert = BertModel.from_pretrained(modelpath)\n",
    "        self.rnn = nn.LSTM(num_layers=2,dropout=0.2, input_size=768, hidden_size=768//2)\n",
    "        self.fc = nn.Linear(384, self.bert.config.vocab_size)\n",
    "        \n",
    "    def forward(self, x,y=None):\n",
    "        \n",
    "        self.bert.train()\n",
    "        encoded_layers, _ = self.bert(x)\n",
    "        for i in encoded_layers:\n",
    "          enc, _ = self.rnn(i)\n",
    "        logits = self.fc(enc)\n",
    "        if y is not None:\n",
    "          loss_fct  = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "          loss = loss_fct(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "          return loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "isEDLjTbI3P3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model = BertLSTM()\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "IimXyW2QJVmA",
    "colab_type": "code",
    "outputId": "1b78e05d-0446-48a7-fa0a-ad931901c7e4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2653.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : 69.75375080108643\n",
      "step 1 : 69.47504615783691\n",
      "step 2 : 69.33349609375\n",
      "step 3 : 69.20606231689453\n",
      "step 4 : 69.0837812423706\n",
      "step 5 : 69.005859375\n",
      "step 6 : 68.85943794250488\n",
      "step 7 : 68.71227645874023\n",
      "step 8 : 68.61512470245361\n",
      "step 9 : 68.47988796234131\n",
      "step 10 : 68.32582092285156\n",
      "step 11 : 68.2575855255127\n",
      "step 12 : 68.09355640411377\n",
      "step 13 : 67.95422458648682\n",
      "step 14 : 67.84716510772705\n",
      "step 15 : 67.74326705932617\n",
      "step 16 : 67.55989933013916\n",
      "step 17 : 67.5284652709961\n",
      "step 18 : 67.3663101196289\n",
      "step 19 : 67.25604057312012\n",
      "step 20 : 67.04909801483154\n",
      "step 21 : 66.87121295928955\n",
      "step 22 : 66.80055904388428\n",
      "step 23 : 66.61228942871094\n",
      "step 24 : 66.55533599853516\n",
      "step 25 : 66.23289680480957\n",
      "step 26 : 66.27696132659912\n",
      "step 27 : 65.88841152191162\n",
      "step 28 : 65.96708011627197\n",
      "step 29 : 65.70754718780518\n",
      "step 30 : 65.48617362976074\n",
      "step 31 : 65.27843379974365\n",
      "step 32 : 65.05558204650879\n",
      "step 33 : 64.87465763092041\n",
      "step 34 : 64.62165260314941\n",
      "step 35 : 64.54038143157959\n",
      "step 36 : 64.16906642913818\n",
      "step 37 : 64.09029293060303\n",
      "step 38 : 63.656073570251465\n",
      "step 39 : 63.38031768798828\n",
      "step 40 : 63.05501747131348\n",
      "step 41 : 62.81746196746826\n",
      "step 42 : 62.385908126831055\n",
      "step 43 : 62.190537452697754\n",
      "step 44 : 61.797027587890625\n",
      "step 45 : 61.65609836578369\n",
      "step 46 : 61.08067321777344\n",
      "step 47 : 60.84504413604736\n",
      "step 48 : 60.58536911010742\n",
      "step 49 : 60.130126953125\n",
      "step 50 : 59.68349552154541\n",
      "step 51 : 59.425360679626465\n",
      "step 52 : 58.82510566711426\n",
      "step 53 : 58.66689109802246\n",
      "step 54 : 58.142531394958496\n",
      "step 55 : 57.489803314208984\n",
      "step 56 : 57.178256034851074\n",
      "step 57 : 56.63110542297363\n",
      "step 58 : 56.21034812927246\n",
      "step 59 : 55.89495611190796\n",
      "step 60 : 55.33402967453003\n",
      "step 61 : 54.770400524139404\n",
      "step 62 : 54.17407846450806\n",
      "step 63 : 53.677632331848145\n",
      "step 64 : 53.17023706436157\n",
      "step 65 : 52.3607759475708\n",
      "step 66 : 52.15623950958252\n",
      "step 67 : 51.48731231689453\n",
      "step 68 : 51.07056760787964\n",
      "step 69 : 50.34197998046875\n",
      "step 70 : 49.88246965408325\n",
      "step 71 : 49.242961406707764\n",
      "step 72 : 48.31897735595703\n",
      "step 73 : 47.89674472808838\n",
      "step 74 : 47.475342750549316\n",
      "step 75 : 46.82109498977661\n",
      "step 76 : 45.839773178100586\n",
      "step 77 : 45.594409465789795\n",
      "step 78 : 44.89943552017212\n",
      "step 79 : 44.375115394592285\n",
      "step 80 : 43.35157918930054\n",
      "step 81 : 43.04516935348511\n",
      "step 82 : 42.4571328163147\n",
      "step 83 : 41.3873929977417\n",
      "step 84 : 40.518574237823486\n",
      "step 85 : 39.97633934020996\n",
      "step 86 : 39.7953519821167\n",
      "step 87 : 39.16308784484863\n",
      "step 88 : 38.34846496582031\n",
      "step 89 : 37.68353080749512\n",
      "step 90 : 36.80702543258667\n",
      "step 91 : 36.439778327941895\n",
      "step 92 : 36.07376480102539\n",
      "step 93 : 35.04281139373779\n",
      "step 94 : 34.79704284667969\n",
      "step 95 : 33.736530780792236\n",
      "step 96 : 33.34035110473633\n",
      "step 97 : 32.75429391860962\n",
      "step 98 : 31.946979522705078\n",
      "step 99 : 30.84333038330078\n",
      "step 100 : 30.143921613693237\n",
      "step 101 : 29.575462102890015\n",
      "step 102 : 29.069363117218018\n",
      "step 103 : 28.451690673828125\n",
      "step 104 : 27.296794652938843\n",
      "step 105 : 27.11205506324768\n",
      "step 106 : 26.88639807701111\n",
      "step 107 : 25.76547884941101\n",
      "step 108 : 25.035441637039185\n",
      "step 109 : 24.587778091430664\n",
      "step 110 : 24.217435359954834\n",
      "step 111 : 23.911603212356567\n",
      "step 112 : 23.101953506469727\n",
      "step 113 : 22.312108516693115\n",
      "step 114 : 21.542147397994995\n",
      "step 115 : 21.38021731376648\n",
      "step 116 : 20.693904399871826\n",
      "step 117 : 20.142772436141968\n",
      "step 118 : 19.570438623428345\n",
      "step 119 : 19.08566164970398\n",
      "step 120 : 18.867591381072998\n",
      "step 121 : 18.15017056465149\n",
      "step 122 : 17.772383451461792\n",
      "step 123 : 17.236581802368164\n",
      "step 124 : 17.44479751586914\n",
      "step 125 : 16.898634910583496\n",
      "step 126 : 16.384413480758667\n",
      "step 127 : 15.758879899978638\n",
      "step 128 : 15.854356527328491\n",
      "step 129 : 15.432105302810669\n",
      "step 130 : 15.581419706344604\n",
      "step 131 : 14.917247533798218\n",
      "step 132 : 14.711933374404907\n",
      "step 133 : 14.449113845825195\n",
      "step 134 : 14.470825672149658\n",
      "step 135 : 13.704237937927246\n",
      "step 136 : 13.85503625869751\n",
      "step 137 : 13.51391339302063\n",
      "step 138 : 13.272137641906738\n",
      "step 139 : 13.224465370178223\n",
      "step 140 : 13.071914672851562\n",
      "step 141 : 12.670945167541504\n",
      "step 142 : 12.750162124633789\n",
      "step 143 : 12.262599229812622\n",
      "step 144 : 12.057861328125\n",
      "step 145 : 11.9350106716156\n",
      "step 146 : 11.832187175750732\n",
      "step 147 : 11.777862310409546\n",
      "step 148 : 11.53517746925354\n",
      "step 149 : 11.56556510925293\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "model.train()\n",
    "for i in range(0,150):\n",
    "  eveloss = 0\n",
    "  for k,v in example_pair.items():\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(k,v)\n",
    "    eveloss += loss.mean().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "TH77VGEAIm5T",
    "colab_type": "code",
    "outputId": "9e3234ec-baf0-4938-b3d2-01f4c8071bdf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我']\n",
      "['搭']\n",
      "['公']\n",
      "['車']\n",
      "['上']\n",
      "['學']\n",
      "['[SEP]']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for k,v in example_pair.items():\n",
    "    predictions = model(k)\n",
    "    predicted_index = torch.argmax(predictions[0,-1]).item()\n",
    "    if predicted_index < model.bert.config.vocab_size:\n",
    "      predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    print(predicted_token)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bert Generate.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
