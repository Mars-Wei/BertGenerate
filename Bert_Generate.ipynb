{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ai0xRngO4xZL",
    "colab_type": "text"
   },
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "-X8ZS575g5BP",
    "colab_type": "code",
    "outputId": "24edbf53-3e6a-4a9f-f35b-688a4963dcfc",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.1)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.127)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.18.4)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.14.6)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.0.1.post2)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.127 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.127)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.22)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.127->boto3->pytorch_pretrained_bert) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.127->boto3->pytorch_pretrained_bert) (2.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.127->boto3->pytorch_pretrained_bert) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "pl_URz9EhMjY",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining ,BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9alyLJZ41kx",
    "colab_type": "text"
   },
   "source": [
    "# Bert Generate One By One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "u2-W9XeqYRtL",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
    "target_text = \"我搭公車上學\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "MdTArBzKhPb2",
    "colab_type": "code",
    "outputId": "09a1afdf-ba4d-49be-d2f7-1b5eee75c27f",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, 2769] 2769\n",
      "9 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, 3022] 3022\n",
      "10 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1062] 1062\n",
      "11 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 6722] 6722\n",
      "12 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '車', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 677] 677\n",
      "13 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '車', '上', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 2119] 2119\n",
      "14 1\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '我', '搭', '公', '車', '上', '學', '[MASK]'] [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 102] 102\n",
      "15 1\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "modelpath = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
    "model = BertForMaskedLM.from_pretrained(modelpath)\n",
    "\n",
    "model.to('cuda')\n",
    "\n",
    "example_pair = dict()\n",
    "\n",
    "for i in range(0,len(target_text)+1):\n",
    "  tokenized_text = tokenizer.tokenize(input_text)\n",
    "  tokenized_text.extend(target_text[:i])\n",
    "  tokenized_text.append('[MASK]')\n",
    "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#   for _ in range(512-len(indexed_tokens)):\n",
    "#     indexed_tokens.append(0)\n",
    "  tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "  \n",
    "  loss_ids = [-1] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
    "  if i == len(target_text):\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))[0])\n",
    "  else:\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(target_text[i])[0])\n",
    "#   for _ in range(512-len(loss_ids)):\n",
    "#     loss_ids.append(-1)\n",
    "  loss_tensors = torch.tensor([loss_ids]).to('cuda')\n",
    "  \n",
    "  example_pair[tokens_tensor] = loss_tensors\n",
    "  print(tokenized_text,loss_ids,loss_ids[-1])\n",
    "  print(len(indexed_tokens),len(loss_tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "a6PRnq8jwb39",
    "colab_type": "code",
    "outputId": "e08ea88c-248b-4ed2-d53b-e3e136d1901c",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,   103]],\n",
      "       device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 2769]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,   103]],\n",
      "       device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 3022]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "           103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 1062]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,   103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 6722]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,  6722,   103]], device='cuda:0'): tensor([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1, 677]],\n",
      "       device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,  6722,   677,   103]], device='cuda:0'): tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1, 2119]], device='cuda:0'), tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,  2769,  3022,\n",
      "          1062,  6722,   677,  2119,   103]], device='cuda:0'): tensor([[ -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,  -1,\n",
      "         102]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "print(example_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "m4WdqbT06r44",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Prepare optimizer\n",
    "param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# hack to remove pooler, which is not used\n",
    "# thus it produce None grad that break apex\n",
    "param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                             lr=5e-5,\n",
    "                             warmup=0.1,\n",
    "                             t_total=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "CmQ3PhWa7I3z",
    "colab_type": "code",
    "outputId": "0cd1df96-951e-41c0-aa1f-ed01754ae39d",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 825.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : 37.36085796356201\n",
      "step 1 : 23.70779514312744\n",
      "step 2 : 21.444865226745605\n",
      "step 3 : 18.553422927856445\n",
      "step 4 : 17.417753219604492\n",
      "step 5 : 16.897245407104492\n",
      "step 6 : 15.978704452514648\n",
      "step 7 : 17.163260459899902\n",
      "step 8 : 16.674589157104492\n",
      "step 9 : 16.660064697265625\n",
      "step 10 : 16.22218418121338\n",
      "step 11 : 16.475232124328613\n",
      "step 12 : 15.244463920593262\n",
      "step 13 : 14.150313377380371\n",
      "step 14 : 16.29252815246582\n",
      "step 15 : 16.90859889984131\n",
      "step 16 : 15.194635391235352\n",
      "step 17 : 17.376182556152344\n",
      "step 18 : 16.083887100219727\n",
      "step 19 : 16.41118049621582\n",
      "step 20 : 15.8125\n",
      "step 21 : 14.576831817626953\n",
      "step 22 : 13.978545188903809\n",
      "step 23 : 16.20425033569336\n",
      "step 24 : 15.351747512817383\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-df96a45107a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0meveloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"step \"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" : \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meveloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mnext_m\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                 \u001b[0mnext_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                 \u001b[0mupdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_m\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'e'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(0,60):\n",
    "  eveloss = 0\n",
    "  for k,v in example_pair.items():\n",
    "    loss = model(k,masked_lm_labels=v)\n",
    "    eveloss += loss.mean().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "epTye3VAZ_5r",
    "colab_type": "code",
    "outputId": "38948021-32d4-4c6c-833b-30841ed24e44",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]']\n",
      "['[PAD]']\n",
      "['[PAD]']\n",
      "['[PAD]']\n",
      "['[PAD]']\n",
      "['[PAD]']\n",
      "['[PAD]']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for k,v in example_pair.items():\n",
    "    predictions = model(k)\n",
    "    predicted_index = torch.argmax(predictions[0,len(predictions[0])-1]).item()\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    if '[SEP]' in predicted_token:\n",
    "      break\n",
    "    print(predicted_token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jJ9Wkaz5AaL",
    "colab_type": "text"
   },
   "source": [
    "# Bert Generate One Time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "wnIbjZHbYUa4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
    "target_text = \"我搭公車上學\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "DMmvXGZe5mLM",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "modelpath = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
    "model = BertForMaskedLM.from_pretrained(modelpath)\n",
    "model.to('cuda')\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(input_text)\n",
    "for i in target_text:\n",
    "  tokenized_text.append('[MASK]')\n",
    "# tokenized_text.append('[SEP]')\n",
    "for _ in range(128-len(tokenized_text)):\n",
    "  tokenized_text.append('[MASK]')\n",
    "# tokenized_text.append('[MASK]')\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "\n",
    "loss_ids = []\n",
    "loss_ids = [-1] * (len(tokenizer.tokenize(input_text)))\n",
    "# loss_ids.extend(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(input_text)))\n",
    "for i in target_text:\n",
    "  loss_ids.append(tokenizer.convert_tokens_to_ids(i)[0])\n",
    "loss_ids.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n",
    "for _ in range(128-len(loss_ids)):\n",
    "  loss_ids.append(-1)\n",
    "loss_tensors = torch.tensor([loss_ids]).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "id": "dxSZyq6D87YX",
    "colab_type": "code",
    "outputId": "828abab5-99a6-4068-8da9-d054ace25e44",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,   151,  8373,  8228,  9467,  8120, 10411,   102,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103,   103,   103,\n",
      "           103,   103,   103,   103,   103,   103,   103,   103]],\n",
      "       device='cuda:0') tensor([[  -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1, 2769, 3022, 1062, 6722,\n",
      "          677, 2119,  102,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,\n",
      "           -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1]], device='cuda:0')\n",
      "['[CLS]', 'i', 'go', 'to', 'school', 'by', 'bus', '[SEP]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_tensor,loss_tensors)\n",
    "print(tokenizer.convert_ids_to_tokens(indexed_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "TtWr0Zs158ZF",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# # Prepare optimizer\n",
    "# param_optimizer = list(model.named_parameters())\n",
    "\n",
    "# # hack to remove pooler, which is not used\n",
    "# # thus it produce None grad that break apex\n",
    "# param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "# no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "# optimizer_grouped_parameters = [\n",
    "#         {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.05},\n",
    "#         {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.01}\n",
    "#         ]\n",
    "# optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "#                              lr=5e-5)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=5e-7)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr = 5e-5, momentum=0.9)\n",
    "optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "id": "RQfnhXCy5_Ag",
    "colab_type": "code",
    "outputId": "939ab622-5e2b-4f31-9c88-b4b6f8de0705",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5472.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : 8.128867149353027\n",
      "step 1 : 6.8241424560546875\n",
      "step 2 : 5.619769096374512\n",
      "step 3 : 5.153357982635498\n",
      "step 4 : 5.289130210876465\n",
      "step 5 : 4.376535892486572\n",
      "step 6 : 4.193200588226318\n",
      "step 7 : 4.259396553039551\n",
      "step 8 : 4.070324420928955\n",
      "step 9 : 3.9747025966644287\n",
      "step 10 : 4.1999101638793945\n",
      "step 11 : 3.933626413345337\n",
      "step 12 : 3.8321549892425537\n",
      "step 13 : 3.891087055206299\n",
      "step 14 : 3.803987741470337\n",
      "step 15 : 3.8564608097076416\n",
      "step 16 : 3.6616151332855225\n",
      "step 17 : 3.6182186603546143\n",
      "step 18 : 3.579364776611328\n",
      "step 19 : 3.6259236335754395\n",
      "step 20 : 3.615184783935547\n",
      "step 21 : 3.3506252765655518\n",
      "step 22 : 3.3550331592559814\n",
      "step 23 : 3.4384877681732178\n",
      "step 24 : 3.405526876449585\n",
      "step 25 : 3.380850315093994\n",
      "step 26 : 3.18172287940979\n",
      "step 27 : 3.339765787124634\n",
      "step 28 : 3.053271770477295\n",
      "step 29 : 3.0905978679656982\n",
      "step 30 : 2.9776012897491455\n",
      "step 31 : 2.66851544380188\n",
      "step 32 : 3.1134982109069824\n",
      "step 33 : 2.7148592472076416\n",
      "step 34 : 2.677067995071411\n",
      "step 35 : 3.0757076740264893\n",
      "step 36 : 2.5521702766418457\n",
      "step 37 : 2.592755079269409\n",
      "step 38 : 2.8541548252105713\n",
      "step 39 : 2.520446300506592\n",
      "step 40 : 2.1440770626068115\n",
      "step 41 : 2.55132794380188\n",
      "step 42 : 2.7948124408721924\n",
      "step 43 : 2.2080044746398926\n",
      "step 44 : 2.200287342071533\n",
      "step 45 : 1.826806902885437\n",
      "step 46 : 2.432993173599243\n",
      "step 47 : 2.2877345085144043\n",
      "step 48 : 1.8775795698165894\n",
      "step 49 : 1.88187575340271\n",
      "step 50 : 2.0004751682281494\n",
      "step 51 : 1.9248992204666138\n",
      "step 52 : 1.742251992225647\n",
      "step 53 : 2.1939241886138916\n",
      "step 54 : 1.8144118785858154\n",
      "step 55 : 2.4377474784851074\n",
      "step 56 : 1.9475600719451904\n",
      "step 57 : 2.1951615810394287\n",
      "step 58 : 1.9477665424346924\n",
      "step 59 : 2.161093235015869\n",
      "step 60 : 1.8250972032546997\n",
      "step 61 : 1.8520969152450562\n",
      "step 62 : 1.527388572692871\n",
      "step 63 : 2.2303483486175537\n",
      "step 64 : 1.8403818607330322\n",
      "step 65 : 1.9020822048187256\n",
      "step 66 : 1.3991941213607788\n",
      "step 67 : 1.7979390621185303\n",
      "step 68 : 1.5158195495605469\n",
      "step 69 : 1.374959945678711\n",
      "step 70 : 1.4375673532485962\n",
      "step 71 : 1.2263413667678833\n",
      "step 72 : 1.086795449256897\n",
      "step 73 : 0.9578434824943542\n",
      "step 74 : 1.237794280052185\n",
      "step 75 : 0.9251827597618103\n",
      "step 76 : 1.1022679805755615\n",
      "step 77 : 1.0404025316238403\n",
      "step 78 : 0.7658659815788269\n",
      "step 79 : 0.8579502105712891\n",
      "step 80 : 1.0198934078216553\n",
      "step 81 : 0.3512449264526367\n",
      "step 82 : 0.5645111799240112\n",
      "step 83 : 0.520854115486145\n",
      "step 84 : 0.4574865698814392\n",
      "step 85 : 0.43569469451904297\n",
      "step 86 : 0.44828006625175476\n",
      "step 87 : 0.16055597364902496\n",
      "step 88 : 0.2577683627605438\n",
      "step 89 : 0.30241870880126953\n",
      "step 90 : 2.5789988040924072\n",
      "step 91 : 0.1832365244626999\n",
      "step 92 : 0.2803540825843811\n",
      "step 93 : 0.3949742913246155\n",
      "step 94 : 0.2239433079957962\n",
      "step 95 : 0.1288178265094757\n",
      "step 96 : 0.2853097915649414\n",
      "step 97 : 0.15969398617744446\n",
      "step 98 : 0.24132129549980164\n",
      "step 99 : 0.7209592461585999\n",
      "step 100 : 0.168990820646286\n",
      "step 101 : 0.2086334228515625\n",
      "step 102 : 0.559463620185852\n",
      "step 103 : 0.22757871448993683\n",
      "step 104 : 0.11056028306484222\n",
      "step 105 : 0.45160946249961853\n",
      "step 106 : 0.44980403780937195\n",
      "step 107 : 0.5887554883956909\n",
      "step 108 : 0.012165342457592487\n",
      "step 109 : 0.03225244954228401\n",
      "step 110 : 0.05673027038574219\n",
      "step 111 : 0.02073015458881855\n",
      "step 112 : 0.014141082763671875\n",
      "step 113 : 0.07299260050058365\n",
      "step 114 : 0.04436465725302696\n",
      "step 115 : 0.0065896171145141125\n",
      "step 116 : 0.06851768493652344\n",
      "step 117 : 0.07495498657226562\n",
      "step 118 : 0.023890631273388863\n",
      "step 119 : 0.04778861999511719\n",
      "step 120 : 0.015826907008886337\n",
      "step 121 : 0.16299574077129364\n",
      "step 122 : 0.05740492790937424\n",
      "step 123 : 0.04639789089560509\n",
      "step 124 : 0.00432286923751235\n",
      "step 125 : 0.0041046142578125\n",
      "step 126 : 0.01197869423776865\n",
      "step 127 : 0.0050912583246827126\n",
      "step 128 : 0.006924765650182962\n",
      "step 129 : 0.0064615523442626\n",
      "step 130 : 0.002887725830078125\n",
      "step 131 : 0.004881722386926413\n",
      "step 132 : 0.00939995888620615\n",
      "step 133 : 0.0018939971923828125\n",
      "step 134 : 0.0033310481812804937\n",
      "step 135 : 0.0029324123170226812\n",
      "step 136 : 0.0015694753965362906\n",
      "step 137 : 0.0009809221373870969\n",
      "step 138 : 0.0013653890928253531\n",
      "step 139 : 0.0017773763975128531\n",
      "step 140 : 0.005358559545129538\n",
      "step 141 : 0.00212451396510005\n",
      "step 142 : 0.002914701122790575\n",
      "step 143 : 0.01049150712788105\n",
      "step 144 : 0.00587817607447505\n",
      "step 145 : 0.0010125295957550406\n",
      "step 146 : 0.00352123798802495\n",
      "step 147 : 0.0014408656861633062\n",
      "step 148 : 0.0018277849303558469\n",
      "step 149 : 0.0020114353392273188\n",
      "step 150 : 0.0005209786468185484\n",
      "step 151 : 0.0006261552916839719\n",
      "step 152 : 0.004769461695104837\n",
      "step 153 : 0.0011345999082550406\n",
      "step 154 : 0.010286331176757812\n",
      "step 155 : 0.0024596622679382563\n",
      "step 156 : 0.0059942519292235374\n",
      "step 157 : 0.0010912759462371469\n",
      "step 158 : 0.0011160714784637094\n",
      "step 159 : 0.021887097507715225\n",
      "step 160 : 0.0023795536253601313\n",
      "step 161 : 0.0008536747773177922\n",
      "step 162 : 0.004699979443103075\n",
      "step 163 : 0.0030735561158508062\n",
      "step 164 : 0.0014010837767273188\n",
      "step 165 : 0.0009907314088195562\n",
      "step 166 : 0.0035332271363586187\n",
      "step 167 : 0.0007087162812240422\n",
      "step 168 : 0.0011994497617706656\n",
      "step 169 : 0.0004779270675498992\n",
      "step 170 : 0.0075936997309327126\n",
      "step 171 : 0.0016386850038543344\n",
      "step 172 : 0.0006771087646484375\n",
      "step 173 : 0.0068683624267578125\n",
      "step 174 : 0.0007149832672439516\n",
      "step 175 : 0.0009076254791580141\n",
      "step 176 : 0.0070413863286376\n",
      "step 177 : 0.0005130767822265625\n",
      "step 178 : 0.0007261548889800906\n",
      "step 179 : 0.0013171604368835688\n",
      "step 180 : 0.005210059229284525\n",
      "step 181 : 0.00464221416041255\n",
      "step 182 : 0.0003711155441123992\n",
      "step 183 : 0.0010664804140105844\n",
      "step 184 : 0.0015125274658203125\n",
      "step 185 : 0.0008166176849044859\n",
      "step 186 : 0.002123424084857106\n",
      "step 187 : 0.00035858154296875\n",
      "step 188 : 0.0024228778202086687\n",
      "step 189 : 0.0010076250182464719\n",
      "step 190 : 0.0011335100280120969\n",
      "step 191 : 0.0008501325501129031\n",
      "step 192 : 0.0012076242128387094\n",
      "step 193 : 0.0036566597409546375\n",
      "step 194 : 0.0042362213134765625\n",
      "step 195 : 0.0013108934508636594\n",
      "step 196 : 0.0006504058837890625\n",
      "step 197 : 0.0007098061614669859\n",
      "step 198 : 0.00036076136166229844\n",
      "step 199 : 0.001598358154296875\n",
      "step 200 : 0.0013247898314148188\n",
      "step 201 : 0.003008433850482106\n",
      "step 202 : 0.0009580339537933469\n",
      "step 203 : 0.00019863674242515117\n",
      "step 204 : 0.0005948203033767641\n",
      "step 205 : 0.0008623940520919859\n",
      "step 206 : 0.001178741455078125\n",
      "step 207 : 0.00041144233546219766\n",
      "step 208 : 0.0015811920166015625\n",
      "step 209 : 0.000400543212890625\n",
      "step 210 : 0.0005686623626388609\n",
      "step 211 : 0.0007147107971832156\n",
      "step 212 : 0.0009217943297699094\n",
      "step 213 : 0.0001730237709125504\n",
      "step 214 : 0.0007752009551040828\n",
      "step 215 : 0.0007217951933853328\n",
      "step 216 : 0.00021089825895614922\n",
      "step 217 : 0.00023433139722328633\n",
      "step 218 : 0.00045422144467011094\n",
      "step 219 : 0.0005662100738845766\n",
      "step 220 : 0.0010771070374175906\n",
      "step 221 : 0.00030926294857636094\n",
      "step 222 : 0.0002967289474327117\n",
      "step 223 : 0.0002841949462890625\n",
      "step 224 : 0.00044468470150604844\n",
      "step 225 : 0.009380340576171875\n",
      "step 226 : 0.0009863717714324594\n",
      "step 227 : 0.0002833775070030242\n",
      "step 228 : 0.0010346004273742437\n",
      "step 229 : 0.0007781982421875\n",
      "step 230 : 0.0003291538741905242\n",
      "step 231 : 0.0006656646728515625\n",
      "step 232 : 0.00026730127865448594\n",
      "step 233 : 0.0007566724671050906\n",
      "step 234 : 0.0006504058837890625\n",
      "step 235 : 0.0008198874420486391\n",
      "step 236 : 0.00028555732569657266\n",
      "step 237 : 0.00030190605320967734\n",
      "step 238 : 0.00054931640625\n",
      "step 239 : 0.0004223414871376008\n",
      "step 240 : 0.0005141667206771672\n",
      "step 241 : 0.0009027208434417844\n",
      "step 242 : 0.00046675544581376016\n",
      "step 243 : 0.0016553060850128531\n",
      "step 244 : 0.00041035242611542344\n",
      "step 245 : 0.0010623931884765625\n",
      "step 246 : 0.0005370549042709172\n",
      "step 247 : 0.00025994438328780234\n",
      "step 248 : 0.00026157923275604844\n",
      "step 249 : 0.00028283256688155234\n",
      "step 250 : 0.0010242462158203125\n",
      "step 251 : 0.0016817365540191531\n",
      "step 252 : 0.0007302420563064516\n",
      "step 253 : 0.0011713845888152719\n",
      "step 254 : 0.0003899165603797883\n",
      "step 255 : 0.0013896396849304438\n",
      "step 256 : 0.0018345968564972281\n",
      "step 257 : 0.0005528586334548891\n",
      "step 258 : 0.0008384159882552922\n",
      "step 259 : 0.0026313236448913813\n",
      "step 260 : 0.0005664825439453125\n",
      "step 261 : 0.0010384151246398687\n",
      "step 262 : 0.00047274999087676406\n",
      "step 263 : 0.00047438484034501016\n",
      "step 264 : 0.0002427782310405746\n",
      "step 265 : 0.0004187992599327117\n",
      "step 266 : 0.0006940024322830141\n",
      "step 267 : 0.0002141680015483871\n",
      "step 268 : 0.0009250640869140625\n",
      "step 269 : 0.0007337842835113406\n",
      "step 270 : 0.0004566737625282258\n",
      "step 271 : 0.00034005302586592734\n",
      "step 272 : 0.00023678371508140117\n",
      "step 273 : 0.0003177097823936492\n",
      "step 274 : 0.0007656642119400203\n",
      "step 275 : 0.0010465894592925906\n",
      "step 276 : 0.00023051669995766133\n",
      "step 277 : 0.0003882816818077117\n",
      "step 278 : 0.00023950848844833672\n",
      "step 279 : 0.00031307764584198594\n",
      "step 280 : 0.0002888270828407258\n",
      "step 281 : 0.000247955322265625\n",
      "step 282 : 0.0003136226150672883\n",
      "step 283 : 0.000644683837890625\n",
      "step 284 : 0.00027520317235030234\n",
      "step 285 : 0.0005640302551910281\n",
      "step 286 : 0.00043623786768876016\n",
      "step 287 : 0.0042482102289795876\n",
      "step 288 : 0.0009114401764236391\n",
      "step 289 : 0.0010563986143097281\n",
      "step 290 : 0.0002283368812641129\n",
      "step 291 : 0.00031226020655594766\n",
      "step 292 : 0.00035258702700957656\n",
      "step 293 : 0.0014566694153472781\n",
      "step 294 : 0.00010626656876411289\n",
      "step 295 : 0.0004967280547134578\n",
      "step 296 : 0.00019618442456703633\n",
      "step 297 : 0.0006305149872787297\n",
      "step 298 : 0.00029345921939238906\n",
      "step 299 : 0.00038746424252167344\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for i in range(0,300):\n",
    "  loss = model(tokens_tensor,masked_lm_labels=loss_tensors)\n",
    "  eveloss = loss.mean().item()\n",
    "  optimizer.zero_grad()\n",
    "  loss.backward()\n",
    "  optimizer.step()\n",
    "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a1tz6P9N4e3g",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  predictions = model(tokens_tensor)\n",
    "  start = len(tokenizer.tokenize(input_text))\n",
    "  while start < len(predictions[0]):\n",
    "    predicted_index = torch.argmax(predictions[0,start]).item()\n",
    "    predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    if '[SEP]' in predicted_token:\n",
    "        break\n",
    "    print(predicted_token)\n",
    "    start+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_Lf5xx8ea9p",
    "colab_type": "text"
   },
   "source": [
    "# Bert Generate LSTM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "vgGoh0YfJQKf",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "input_text = \"[CLS] I go to school by bus [SEP] \"\n",
    "target_text = \"我搭公車上學\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "iMM-Kq7aKden",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "modelpath = \"bert-base-chinese\"\n",
    "tokenizer = BertTokenizer.from_pretrained(modelpath)\n",
    "example_pair = dict()\n",
    "\n",
    "for i in range(0,len(target_text)+1):\n",
    "  tokenized_text = tokenizer.tokenize(input_text)\n",
    "  tokenized_text.extend(target_text[:i])\n",
    "  tokenized_text.append('[MASK]')\n",
    "  indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "  tokens_tensor = torch.tensor([indexed_tokens]).to('cuda')\n",
    "  \n",
    "  loss_ids = [-1] * (len(tokenizer.convert_tokens_to_ids(tokenized_text))-1)\n",
    "  if i == len(target_text):\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(tokenizer.tokenize('[SEP]'))[0])\n",
    "  else:\n",
    "    loss_ids.append(tokenizer.convert_tokens_to_ids(target_text[i])[0])\n",
    "  loss_tensors = torch.tensor([loss_ids]).to('cuda')\n",
    "  \n",
    "  example_pair[tokens_tensor] = loss_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "a-7whGubegWn",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "class BertLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        modelpath = \"bert-base-chinese\"\n",
    "        self.bert = BertModel.from_pretrained(modelpath)\n",
    "        self.rnn = nn.LSTM(num_layers=2,dropout=0.2, input_size=768, hidden_size=768//2)\n",
    "        self.fc = nn.Linear(384, self.bert.config.vocab_size)\n",
    "        \n",
    "    def forward(self, x,y=None):\n",
    "        \n",
    "        self.bert.train()\n",
    "        encoded_layers, _ = self.bert(x)\n",
    "        for i in encoded_layers:\n",
    "          enc, _ = self.rnn(i)\n",
    "        logits = self.fc(enc)\n",
    "        if y is not None:\n",
    "          loss_fct  = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "          loss = loss_fct(logits.view(-1, logits.shape[-1]), y.view(-1))\n",
    "          return loss\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "isEDLjTbI3P3",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "model = BertLSTM()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "IimXyW2QJVmA",
    "colab_type": "code",
    "outputId": "4243a41e-1b11-4e95-8e8c-b0ee45166fed",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1935.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 : 15.10863208770752\n",
      "step 1 : 15.151559352874756\n",
      "step 2 : 15.35487985610962\n",
      "step 3 : 15.099365234375\n",
      "step 4 : 14.601593494415283\n",
      "step 5 : 15.178351879119873\n",
      "step 6 : 15.133653163909912\n",
      "step 7 : 15.380486011505127\n",
      "step 8 : 14.865607738494873\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-7814b41db560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexample_pair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0meveloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-ccf83ca8eb3b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mencoded_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0menc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    712\u001b[0m         encoded_layers = self.encoder(embedding_output,\n\u001b[1;32m    713\u001b[0m                                       \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                                       output_all_encoded_layers=output_all_encoded_layers)\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoded_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_all_encoded_layers)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mall_encoder_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_module\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0mall_encoder_layers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tensor, attention_mask)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0mself_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# Normalize the attention scores to probabilities.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "model.train()\n",
    "for i in range(0,115):\n",
    "  eveloss = 0\n",
    "  optimizer.zero_grad()\n",
    "  for k,v in example_pair.items():\n",
    "    loss = model(k,v)\n",
    "    eveloss += loss.mean().item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print(\"step \"+ str(i) + \" : \" + str(eveloss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "TH77VGEAIm5T",
    "colab_type": "code",
    "outputId": "b3a27203-78ec-43f0-8042-7cc355fc89b3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145.0
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我']\n",
      "['我']\n",
      "['我']\n",
      "['我']\n",
      "['我']\n",
      "['我']\n",
      "['我']\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "for k,v in example_pair.items():\n",
    "    predictions = model(k)\n",
    "    predicted_index = torch.argmax(predictions[0,-1]).item()\n",
    "    if predicted_index < model.bert.config.vocab_size:\n",
    "      predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n",
    "    print(predicted_token)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Bert Generate.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
